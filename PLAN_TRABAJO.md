# Pr√°ctica 3 - Competici√≥n Kaggle: Clasificaci√≥n de Hojas de Tomate
## Inteligencia de Negocio - Curso 2025-2026

---

## üìã Informaci√≥n General

| Campo | Valor |
|-------|-------|
| **Asignatura** | Inteligencia de Negocio |
| **Pr√°ctica** | P3 - Competici√≥n Kaggle |
| **Fecha l√≠mite** | 7 de enero de 2026, 23:30 |
| **Puntuaci√≥n m√°xima** | 2.5 puntos |
| **M√©trica de evaluaci√≥n** | F1-score |
| **Nombre en Kaggle** | [TuNombre][TuApellido]_UGR_IN |

---

## üéØ Objetivo del Problema

Clasificaci√≥n binaria de hojas de tomate:
- **Clase 0 (control)**: Hojas sanas
- **Clase 1 (botrytis)**: Hojas infectadas

### Datos Disponibles

| Archivo | Descripci√≥n | Tama√±o |
|---------|-------------|--------|
| `train.csv` | Conjunto de entrenamiento con etiquetas | 337 muestras |
| `test.csv` | Conjunto de test sin etiquetas | 144 muestras |
| `sample_submission.csv` | Formato de env√≠o | 144 filas |

### Variables del Dataset

| Tipo | Columnas | Descripci√≥n |
|------|----------|-------------|
| **Metadatos (NO USAR)** | `exp`, `dpi`, `leaf`, `spot` | Informaci√≥n experimental |
| **Fluorescencia** | `F440`, `F520`, `F680`, `F740` | 4 valores de fluorescencia multicolor |
| **Hiperespectral** | `w388.13` a `w1028.28` | ~300 variables espectrales (longitudes de onda) |
| **Target** | `class` | `control` (0) o `botrytis` (1) |

---

## üìÅ Estructura del Proyecto

```
P3/
‚îú‚îÄ‚îÄ data/                      # Datos originales (NO MODIFICAR)
‚îÇ   ‚îú‚îÄ‚îÄ train.csv
‚îÇ   ‚îú‚îÄ‚îÄ test.csv
‚îÇ   ‚îî‚îÄ‚îÄ sample_submission.csv
‚îú‚îÄ‚îÄ notebooks/                 # Jupyter notebooks de experimentaci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ 01_EDA.ipynb          # An√°lisis exploratorio inicial
‚îú‚îÄ‚îÄ src/                       # C√≥digo fuente reutilizable
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py       # Funciones de preprocesado
‚îÇ   ‚îú‚îÄ‚îÄ models.py             # Definici√≥n de modelos
‚îÇ   ‚îî‚îÄ‚îÄ utils.py              # Utilidades generales
‚îú‚îÄ‚îÄ submissions/               # Archivos CSV enviados a Kaggle
‚îÇ   ‚îî‚îÄ‚îÄ README.md             # √çndice de submissions
‚îú‚îÄ‚îÄ scripts/                   # Scripts de experimentos
‚îÇ   ‚îî‚îÄ‚îÄ README.md             # Descripci√≥n de cada script
‚îú‚îÄ‚îÄ docs/                      # Documentaci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ capturas/             # Capturas de pantalla de Kaggle
‚îú‚îÄ‚îÄ PLAN_TRABAJO.md           # Este archivo
‚îú‚îÄ‚îÄ REGISTRO_EXPERIMENTOS.md  # Tabla de experimentos (OBLIGATORIO)
‚îî‚îÄ‚îÄ requirements.txt          # Dependencias del proyecto
```

---

## üó∫Ô∏è Ruta de Trabajo

### Fase 1: Configuraci√≥n y EDA (An√°lisis Exploratorio)
- [x] **1.1** Configurar entorno de trabajo y dependencias ‚úÖ
- [x] **1.2** Cargar y explorar los datos ‚úÖ
- [x] **1.3** An√°lisis de distribuci√≥n de clases (balance/desbalance) ‚úÖ
- [x] **1.4** Visualizaci√≥n de variables de fluorescencia ‚úÖ
- [x] **1.5** Visualizaci√≥n de espectros hiperespectrales ‚úÖ
- [x] **1.6** An√°lisis de correlaciones entre variables ‚úÖ
- [x] **1.7** Detecci√≥n de valores at√≠picos (outliers) ‚úÖ
- [x] **1.8** Documentar hallazgos del EDA ‚úÖ

### Fase 2: Preprocesamiento de Datos
- [x] **2.1** Separar variables v√°lidas de metadatos ‚úÖ
- [x] **2.2** An√°lisis de valores faltantes ‚úÖ (No hay valores faltantes)
- [x] **2.3** Normalizaci√≥n/Estandarizaci√≥n de datos ‚úÖ (StandardScaler implementado)
- [x] **2.4** Reducci√≥n de dimensionalidad (PCA, selecci√≥n de caracter√≠sticas) ‚úÖ (PCA y SelectKBest implementados)
- [ ] **2.5** T√©cnicas de balanceo de clases (si aplica: SMOTE, undersampling) - Pendiente evaluar necesidad
- [x] **2.6** Crear pipeline de preprocesamiento reutilizable ‚úÖ (src/preprocessing.py)

### Fase 3: Modelado Baseline
- [x] **3.1** Implementar validaci√≥n cruzada estratificada ‚úÖ (StratifiedKFold 5-fold)
- [x] **3.2** Entrenar modelo baseline simple (Logistic Regression / Decision Tree) ‚úÖ
- [x] **3.3** Evaluar con F1-score en validaci√≥n ‚úÖ (LogReg: 0.9388, RF: 0.9266, SVM: 0.9326)
- [x] **3.4** Primera submission a Kaggle ‚úÖ (submission_01_baseline_logisticregression)
- [ ] **3.5** Documentar resultados en tabla de experimentos - Pendiente score Kaggle

### Fase 4: Experimentaci√≥n con Modelos
- [ ] **4.1** Random Forest
- [ ] **4.2** Gradient Boosting (XGBoost, LightGBM, CatBoost)
- [ ] **4.3** Support Vector Machine (SVM)
- [ ] **4.4** K-Nearest Neighbors (KNN)
- [ ] **4.5** Redes Neuronales (MLP)
- [ ] **4.6** Comparativa de modelos

### Fase 5: Optimizaci√≥n
- [ ] **5.1** B√∫squeda de hiperpar√°metros (GridSearch / RandomSearch / Optuna)
- [ ] **5.2** Feature Engineering avanzado
- [ ] **5.3** Ensemble methods (Voting, Stacking)
- [ ] **5.4** An√°lisis de importancia de caracter√≠sticas
- [ ] **5.5** Validaci√≥n cruzada anidada para estimaci√≥n robusta

### Fase 6: Submissions Finales
- [ ] **6.1** Seleccionar mejores modelos
- [ ] **6.2** Entrenar con todos los datos de entrenamiento
- [ ] **6.3** Generar predicciones finales
- [ ] **6.4** Submissions estrat√©gicas a Kaggle

### Fase 7: Documentaci√≥n Final
- [ ] **7.1** Completar tabla de experimentos
- [ ] **7.2** Captura de pantalla del Leaderboard
- [ ] **7.3** Redactar documentaci√≥n PDF
- [ ] **7.4** Organizar scripts y CSVs con nomenclatura clara
- [ ] **7.5** Revisi√≥n final y entrega

---

## üìä Registro de Experimentos

> **IMPORTANTE**: Mantener actualizado el archivo `REGISTRO_EXPERIMENTOS.md` con cada submission.

Ver archivo: [REGISTRO_EXPERIMENTOS.md](./REGISTRO_EXPERIMENTOS.md)

---

## üìù Registro de Progreso

### [Fecha: 23/12/2024]
**Actividad realizada:**
- Configuraci√≥n inicial del proyecto y estructura de directorios
- Implementaci√≥n de m√≥dulos en `src/`: preprocessing.py, models.py, utils.py
- An√°lisis Exploratorio de Datos completo (notebook 01_EDA.ipynb)
- Entrenamiento y comparaci√≥n de 5 modelos baseline
- Generaci√≥n de primera submission para Kaggle

**Problemas encontrados:**
- Datos con formato incorrecto: valores como '232 .25' (espacio antes del punto decimal)
- Error al calcular correlaciones por tipos de datos incorrectos

**Soluciones aplicadas:**
- Implementaci√≥n de funci√≥n `clean_numeric_columns()` en preprocessing.py
- Integraci√≥n de limpieza autom√°tica en `load_data()`

**Pr√≥ximos pasos:**
- Subir submission a Kaggle y registrar score
- Experimentar con PCA + diferentes modelos
- Probar XGBoost/LightGBM
- Optimizaci√≥n de hiperpar√°metros

---

## üîß Notas T√©cnicas

### Librer√≠as Recomendadas
```python
# Data manipulation
pandas, numpy

# Visualization
matplotlib, seaborn, plotly

# Machine Learning
scikit-learn, xgboost, lightgbm, catboost

# Imbalanced data
imbalanced-learn (SMOTE, etc.)

# Hyperparameter tuning
optuna, scikit-optimize

# Deep Learning (opcional)
tensorflow, pytorch
```

### Consideraciones Especiales
1. **NO usar** columnas `exp`, `dpi`, `leaf`, `spot` como features
2. **Codificaci√≥n de clases**: control ‚Üí 0, botrytis ‚Üí 1
3. **M√©trica objetivo**: F1-score
4. **Validaci√≥n**: Usar validaci√≥n cruzada estratificada por el desbalance potencial

---

## ‚ö†Ô∏è Recordatorios Importantes

- [ ] Registrar CADA submission en la tabla de experimentos
- [ ] Guardar CADA script usado con nomenclatura clara (ej: `exp_01_baseline_lr.py`)
- [ ] Guardar CADA CSV de submission (ej: `submission_01_baseline_lr.csv`)
- [ ] No usar datos de test para entrenar/configurar modelos
- [ ] Nombre en Kaggle: `[Nombre][Apellido]_UGR_IN`
- [ ] Captura del Leaderboard para la documentaci√≥n

---

## üìö Referencias y Recursos

- [Documentaci√≥n scikit-learn](https://scikit-learn.org/)
- [XGBoost Documentation](https://xgboost.readthedocs.io/)
- [Imbalanced-learn](https://imbalanced-learn.org/)
- [Kaggle Competition Tips](https://www.kaggle.com/docs/competitions)

---

*√öltima actualizaci√≥n: 23/12/2024*
